{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing data for a recurrent neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A recurrent neural network requires a 3D array as input. The first dimension is the number of samples, the second dimension is the number of time steps, and the third dimension is the number of features. The following code creates a 3D array with 3 samples, 2 time steps, and 1 feature.\n",
    "\n",
    "Let's say we want to predict the next day after sequence of 3 days.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we want to predict the next day after sequence of 3 days.  \n",
    "\n",
    "Here is the data we will use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temp</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Pressure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-04-01</th>\n",
       "      <td>77</td>\n",
       "      <td>50</td>\n",
       "      <td>29.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-02</th>\n",
       "      <td>78</td>\n",
       "      <td>51</td>\n",
       "      <td>29.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-03</th>\n",
       "      <td>79</td>\n",
       "      <td>52</td>\n",
       "      <td>29.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-04</th>\n",
       "      <td>80</td>\n",
       "      <td>53</td>\n",
       "      <td>29.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-05</th>\n",
       "      <td>78</td>\n",
       "      <td>67</td>\n",
       "      <td>29.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-06</th>\n",
       "      <td>82</td>\n",
       "      <td>59</td>\n",
       "      <td>29.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-07</th>\n",
       "      <td>76</td>\n",
       "      <td>58</td>\n",
       "      <td>29.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-08</th>\n",
       "      <td>76</td>\n",
       "      <td>56</td>\n",
       "      <td>29.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-09</th>\n",
       "      <td>85</td>\n",
       "      <td>62</td>\n",
       "      <td>30.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-10</th>\n",
       "      <td>73</td>\n",
       "      <td>55</td>\n",
       "      <td>30.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Temp  Humidity  Pressure\n",
       "2023-04-01    77        50     29.92\n",
       "2023-04-02    78        51     29.93\n",
       "2023-04-03    79        52     29.94\n",
       "2023-04-04    80        53     29.95\n",
       "2023-04-05    78        67     29.96\n",
       "2023-04-06    82        59     29.97\n",
       "2023-04-07    76        58     29.98\n",
       "2023-04-08    76        56     29.99\n",
       "2023-04-09    85        62     30.00\n",
       "2023-04-10    73        55     30.01"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(\n",
    "    data={\n",
    "        'Temp':[77,78,79,80,78,82,76,76,85,73], \n",
    "        'Humidity': [50,51,52,53,67,59,58,56,62,55], \n",
    "        'Pressure': [29.92,29.93,29.94,29.95, 29.96,29.97,29.98,29.99,30.00,30.01]\n",
    "    }, \n",
    "    index=['2023-04-01','2023-04-02','2023-04-03','2023-04-04', '2023-04-05','2023-04-06','2023-04-07','2023-04-08','2023-04-09','2023-04-10'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering the parameters of this problem we find that our first sample (observation) will be the feature values for the first 3 rows of the dataframe, and the second sample (observation) will be the next three rows starting at the second row, etc.\n",
    "\n",
    "Let's begin by converting the dataframe to a numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[77.  , 50.  , 29.92],\n",
       "       [78.  , 51.  , 29.93],\n",
       "       [79.  , 52.  , 29.94],\n",
       "       [80.  , 53.  , 29.95],\n",
       "       [78.  , 67.  , 29.96],\n",
       "       [82.  , 59.  , 29.97],\n",
       "       [76.  , 58.  , 29.98],\n",
       "       [76.  , 56.  , 29.99],\n",
       "       [85.  , 62.  , 30.  ],\n",
       "       [73.  , 55.  , 30.01]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr2D = df.to_numpy() # convert the dataframe to a numpy array\n",
    "arr2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 2D data above is not not our input to the recurrent network - we have three feaures, but no observations. Observations will be the sequences length number of rows.\n",
    "\n",
    "This might be easier to understand if we look at how we can manually create observations for our recurrent network training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[77.  , 50.  , 29.92],\n",
       "       [78.  , 51.  , 29.93],\n",
       "       [79.  , 52.  , 29.94]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr2D[0:3,:]  # this would be the first observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[78.  , 51.  , 29.93],\n",
       "       [79.  , 52.  , 29.94],\n",
       "       [80.  , 53.  , 29.95]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr2D[1:4,:]  # this would be the second observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[79.  , 52.  , 29.94],\n",
       "       [80.  , 53.  , 29.95],\n",
       "       [78.  , 67.  , 29.96]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr2D[2:5,:]  # this would be the third observation, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But, this would be better to put into a function as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data, seq_length):\n",
    "    obs = []\n",
    "    print(obs)    \n",
    "    for i in range(len(data)-seq_length-1):\n",
    "        obs.append(data[i:(i+seq_length)+1])\n",
    "    return np.array(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[77.  , 50.  , 29.92],\n",
       "        [78.  , 51.  , 29.93],\n",
       "        [79.  , 52.  , 29.94],\n",
       "        [80.  , 53.  , 29.95]],\n",
       "\n",
       "       [[78.  , 51.  , 29.93],\n",
       "        [79.  , 52.  , 29.94],\n",
       "        [80.  , 53.  , 29.95],\n",
       "        [78.  , 67.  , 29.96]],\n",
       "\n",
       "       [[79.  , 52.  , 29.94],\n",
       "        [80.  , 53.  , 29.95],\n",
       "        [78.  , 67.  , 29.96],\n",
       "        [82.  , 59.  , 29.97]],\n",
       "\n",
       "       [[80.  , 53.  , 29.95],\n",
       "        [78.  , 67.  , 29.96],\n",
       "        [82.  , 59.  , 29.97],\n",
       "        [76.  , 58.  , 29.98]],\n",
       "\n",
       "       [[78.  , 67.  , 29.96],\n",
       "        [82.  , 59.  , 29.97],\n",
       "        [76.  , 58.  , 29.98],\n",
       "        [76.  , 56.  , 29.99]],\n",
       "\n",
       "       [[82.  , 59.  , 29.97],\n",
       "        [76.  , 58.  , 29.98],\n",
       "        [76.  , 56.  , 29.99],\n",
       "        [85.  , 62.  , 30.  ]]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RNN_input = create_sequences(arr2D, 3)\n",
    "RNN_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review the data we have created above.  We have 6 'observations', each with 3 time steps and 3 features (Temp, Humidity and Pressure).  The last row of each observation is the target value we want to predict. We only need the temp value from the last row of each observation (the other values are not needed - because if you're trying to predict tomorrow's weather, you don't have any measures from tomorrow, because it's the future :) )."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now extract our target variable. In this case, we want to predict the next day's temperature, so we will extract the last temperature value from each sequence (observation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([80., 78., 82., 76., 76., 85.])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = RNN_input[:,-1,0] # the 3 is the index of the column, and the 0 is the index of the row\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[77.  , 50.  , 29.92],\n",
       "        [78.  , 51.  , 29.93],\n",
       "        [79.  , 52.  , 29.94]],\n",
       "\n",
       "       [[78.  , 51.  , 29.93],\n",
       "        [79.  , 52.  , 29.94],\n",
       "        [80.  , 53.  , 29.95]],\n",
       "\n",
       "       [[79.  , 52.  , 29.94],\n",
       "        [80.  , 53.  , 29.95],\n",
       "        [78.  , 67.  , 29.96]],\n",
       "\n",
       "       [[80.  , 53.  , 29.95],\n",
       "        [78.  , 67.  , 29.96],\n",
       "        [82.  , 59.  , 29.97]],\n",
       "\n",
       "       [[78.  , 67.  , 29.96],\n",
       "        [82.  , 59.  , 29.97],\n",
       "        [76.  , 58.  , 29.98]],\n",
       "\n",
       "       [[82.  , 59.  , 29.97],\n",
       "        [76.  , 58.  , 29.98],\n",
       "        [76.  , 56.  , 29.99]]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = RNN_input[:,0:3,0:3] # the 3 is the index of the column, and the 0 is the index of the row\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the data to a Recurrent neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[85.],\n",
       "       [82.],\n",
       "       [76.],\n",
       "       [76.]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = y_train.reshape(-1,1)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[80.],\n",
       "       [78.]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = y_test.reshape(-1,1)\n",
    "y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 3, 3)\n",
      "(2, 3, 3)\n",
      "(4, 1)\n",
      "(2, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to split out data into train and test and normalize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[77.  , 50.  , 29.92, 78.  , 51.  , 29.93, 79.  , 52.  , 29.94],\n",
       "       [78.  , 51.  , 29.93, 79.  , 52.  , 29.94, 80.  , 53.  , 29.95]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.reshape(-1, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 3, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[82.  , 59.  , 29.97],\n",
       "        [76.  , 58.  , 29.98],\n",
       "        [76.  , 56.  , 29.99]],\n",
       "\n",
       "       [[79.  , 52.  , 29.94],\n",
       "        [80.  , 53.  , 29.95],\n",
       "        [78.  , 67.  , 29.96]],\n",
       "\n",
       "       [[78.  , 67.  , 29.96],\n",
       "        [82.  , 59.  , 29.97],\n",
       "        [76.  , 58.  , 29.98]],\n",
       "\n",
       "       [[80.  , 53.  , 29.95],\n",
       "        [78.  , 67.  , 29.96],\n",
       "        [82.  , 59.  , 29.97]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[82.  , 59.  , 29.97],\n",
       "       [76.  , 58.  , 29.98],\n",
       "       [76.  , 56.  , 29.99],\n",
       "       [79.  , 52.  , 29.94],\n",
       "       [80.  , 53.  , 29.95],\n",
       "       [78.  , 67.  , 29.96],\n",
       "       [78.  , 67.  , 29.96],\n",
       "       [82.  , 59.  , 29.97],\n",
       "       [76.  , 58.  , 29.98],\n",
       "       [80.  , 53.  , 29.95],\n",
       "       [78.  , 67.  , 29.96],\n",
       "       [82.  , 59.  , 29.97]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.reshape(-1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[82.  , 59.  , 29.97],\n",
       "        [76.  , 58.  , 29.98],\n",
       "        [76.  , 56.  , 29.99]],\n",
       "\n",
       "       [[79.  , 52.  , 29.94],\n",
       "        [80.  , 53.  , 29.95],\n",
       "        [78.  , 67.  , 29.96]],\n",
       "\n",
       "       [[78.  , 67.  , 29.96],\n",
       "        [82.  , 59.  , 29.97],\n",
       "        [76.  , 58.  , 29.98]],\n",
       "\n",
       "       [[80.  , 53.  , 29.95],\n",
       "        [78.  , 67.  , 29.96],\n",
       "        [82.  , 59.  , 29.97]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.reshape(-1, 3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MinMaxScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "X_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X_train_scaled = X_scaler.fit_transform(X_train.reshape(-1, 3))\n",
    "X_test_scaled = X_scaler.transform(X_train.reshape(-1, 3))\n",
    "\n",
    "\n",
    "y_scaler = MinMaxScaler(feature_range=(0, 1)) # I don't necessarily need to rescale the y values, but I may test doing this in the future\n",
    "y_scaler.fit(y_train.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 3)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1.        , 0.46666667, 0.6       ],\n",
       "        [0.        , 0.4       , 0.8       ],\n",
       "        [0.        , 0.26666667, 1.        ]],\n",
       "\n",
       "       [[0.5       , 0.        , 0.        ],\n",
       "        [0.66666667, 0.06666667, 0.2       ],\n",
       "        [0.33333333, 1.        , 0.4       ]],\n",
       "\n",
       "       [[0.33333333, 1.        , 0.4       ],\n",
       "        [1.        , 0.46666667, 0.6       ],\n",
       "        [0.        , 0.4       , 0.8       ]],\n",
       "\n",
       "       [[0.66666667, 0.06666667, 0.2       ],\n",
       "        [0.33333333, 1.        , 0.4       ],\n",
       "        [1.        , 0.46666667, 0.6       ]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled.reshape(-1, 3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.46666667, 0.6       ],\n",
       "       [0.        , 0.4       , 0.8       ],\n",
       "       [0.        , 0.26666667, 1.        ],\n",
       "       [0.5       , 0.        , 0.        ],\n",
       "       [0.66666667, 0.06666667, 0.2       ],\n",
       "       [0.33333333, 1.        , 0.4       ],\n",
       "       [0.33333333, 1.        , 0.4       ],\n",
       "       [1.        , 0.46666667, 0.6       ],\n",
       "       [0.        , 0.4       , 0.8       ],\n",
       "       [0.66666667, 0.06666667, 0.2       ],\n",
       "       [0.33333333, 1.        , 0.4       ],\n",
       "       [1.        , 0.46666667, 0.6       ]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to fit the data to a recurrent neural network.  We will use a simple RNN with 20 neurons in the hidden layer.  We will use the mean squared error loss function and the adam optimizer. Our input consists of 6 observations, each with 3 time steps and 3 features.  Our target is the temperature value for the last time step of each observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import SimpleRNN, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(20, input_shape=(3,3)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn (SimpleRNN)      (None, 20)                480       \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 501\n",
      "Trainable params: 501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "4/4 [==============================] - 2s 8ms/step - loss: 6517.4111\n",
      "Epoch 2/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 6456.1855\n",
      "Epoch 3/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 6409.6768\n",
      "Epoch 4/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 6376.1895\n",
      "Epoch 5/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 6352.7656\n",
      "Epoch 6/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 6330.8687\n",
      "Epoch 7/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 6305.9941\n",
      "Epoch 8/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 6281.0859\n",
      "Epoch 9/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 6253.6191\n",
      "Epoch 10/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 6223.8135\n",
      "Epoch 11/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 6203.7910\n",
      "Epoch 12/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 6186.2134\n",
      "Epoch 13/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 6168.2993\n",
      "Epoch 14/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 6141.8867\n",
      "Epoch 15/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 6104.0732\n",
      "Epoch 16/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 6082.5259\n",
      "Epoch 17/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 6066.2441\n",
      "Epoch 18/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 6050.9878\n",
      "Epoch 19/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 6034.3545\n",
      "Epoch 20/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 6008.7651\n",
      "Epoch 21/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 5979.2764\n",
      "Epoch 22/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 5944.9883\n",
      "Epoch 23/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 5925.3066\n",
      "Epoch 24/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 5911.6748\n",
      "Epoch 25/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 5898.9595\n",
      "Epoch 26/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 5886.0117\n",
      "Epoch 27/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 5873.2505\n",
      "Epoch 28/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 5860.5688\n",
      "Epoch 29/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 5847.9346\n",
      "Epoch 30/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 5835.2334\n",
      "Epoch 31/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 5822.7441\n",
      "Epoch 32/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 5809.9512\n",
      "Epoch 33/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 5797.4624\n",
      "Epoch 34/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 5784.7607\n",
      "Epoch 35/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 5772.4941\n",
      "Epoch 36/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 5759.6943\n",
      "Epoch 37/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 5747.3271\n",
      "Epoch 38/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 5734.6172\n",
      "Epoch 39/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 5722.2881\n",
      "Epoch 40/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 5709.8242\n",
      "Epoch 41/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 5697.3276\n",
      "Epoch 42/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 5684.8486\n",
      "Epoch 43/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 5672.5586\n",
      "Epoch 44/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 5660.0479\n",
      "Epoch 45/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 5647.7607\n",
      "Epoch 46/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 5635.3457\n",
      "Epoch 47/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 5623.0166\n",
      "Epoch 48/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 5610.8574\n",
      "Epoch 49/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 5598.3242\n",
      "Epoch 50/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 5586.1162\n",
      "Epoch 51/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 5573.9824\n",
      "Epoch 52/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 5561.8096\n",
      "Epoch 53/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 5549.4644\n",
      "Epoch 54/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 5537.4199\n",
      "Epoch 55/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 5525.3003\n",
      "Epoch 56/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 5512.9487\n",
      "Epoch 57/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 5500.6738\n",
      "Epoch 58/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 5487.6470\n",
      "Epoch 59/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 5473.0249\n",
      "Epoch 60/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 5442.6714\n",
      "Epoch 61/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 5415.4775\n",
      "Epoch 62/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 5396.3286\n",
      "Epoch 63/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 5377.2417\n",
      "Epoch 64/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 5362.5225\n",
      "Epoch 65/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 5349.6338\n",
      "Epoch 66/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 5337.9053\n",
      "Epoch 67/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 5325.9619\n",
      "Epoch 68/500\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 5314.4170\n",
      "Epoch 69/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 5302.6553\n",
      "Epoch 70/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 5290.7607\n",
      "Epoch 71/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 5279.0703\n",
      "Epoch 72/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 5267.4292\n",
      "Epoch 73/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 5255.7856\n",
      "Epoch 74/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 5244.0928\n",
      "Epoch 75/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 5232.4375\n",
      "Epoch 76/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 5220.7842\n",
      "Epoch 77/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 5209.0210\n",
      "Epoch 78/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 5197.5352\n",
      "Epoch 79/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 5186.0283\n",
      "Epoch 80/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 5174.5156\n",
      "Epoch 81/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 5162.8477\n",
      "Epoch 82/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 5151.2832\n",
      "Epoch 83/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 5139.8223\n",
      "Epoch 84/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 5128.1611\n",
      "Epoch 85/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 5116.7393\n",
      "Epoch 86/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 5105.3662\n",
      "Epoch 87/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 5093.9795\n",
      "Epoch 88/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 5082.5059\n",
      "Epoch 89/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 5071.3135\n",
      "Epoch 90/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 5059.7783\n",
      "Epoch 91/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 5048.4189\n",
      "Epoch 92/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 5036.8994\n",
      "Epoch 93/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 5025.7515\n",
      "Epoch 94/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 5014.3311\n",
      "Epoch 95/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 5003.2080\n",
      "Epoch 96/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 4991.9165\n",
      "Epoch 97/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 4980.5625\n",
      "Epoch 98/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 4969.4702\n",
      "Epoch 99/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 4958.1025\n",
      "Epoch 100/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 4946.8511\n",
      "Epoch 101/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 4935.7090\n",
      "Epoch 102/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 4924.7646\n",
      "Epoch 103/500\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 4913.3555\n",
      "Epoch 104/500\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 4902.3208\n",
      "Epoch 105/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 4891.2051\n",
      "Epoch 106/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 4880.3511\n",
      "Epoch 107/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 4869.1924\n",
      "Epoch 108/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 4858.0562\n",
      "Epoch 109/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 4846.8833\n",
      "Epoch 110/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 4835.9785\n",
      "Epoch 111/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 4824.8984\n",
      "Epoch 112/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 4814.1270\n",
      "Epoch 113/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 4803.1260\n",
      "Epoch 114/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 4792.1289\n",
      "Epoch 115/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 4781.2485\n",
      "Epoch 116/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 4770.3208\n",
      "Epoch 117/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 4759.5288\n",
      "Epoch 118/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 4748.3828\n",
      "Epoch 119/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 4737.6074\n",
      "Epoch 120/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 4726.8027\n",
      "Epoch 121/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 4716.1758\n",
      "Epoch 122/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 4705.2090\n",
      "Epoch 123/500\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 4694.5952\n",
      "Epoch 124/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 4683.7002\n",
      "Epoch 125/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 4672.9600\n",
      "Epoch 126/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 4662.2363\n",
      "Epoch 127/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 4651.4771\n",
      "Epoch 128/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 4640.8711\n",
      "Epoch 129/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 4630.1543\n",
      "Epoch 130/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 4619.4053\n",
      "Epoch 131/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 4608.8057\n",
      "Epoch 132/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 4598.3477\n",
      "Epoch 133/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 4587.6523\n",
      "Epoch 134/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4577.0996\n",
      "Epoch 135/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 4566.4893\n",
      "Epoch 136/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 4556.1001\n",
      "Epoch 137/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 4545.4971\n",
      "Epoch 138/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 4534.7490\n",
      "Epoch 139/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 4524.5264\n",
      "Epoch 140/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 4514.0635\n",
      "Epoch 141/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 4503.5171\n",
      "Epoch 142/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 4492.8994\n",
      "Epoch 143/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 4482.4780\n",
      "Epoch 144/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4472.1660\n",
      "Epoch 145/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 4461.9058\n",
      "Epoch 146/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 4451.3906\n",
      "Epoch 147/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4441.0986\n",
      "Epoch 148/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 4430.9097\n",
      "Epoch 149/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 4420.5117\n",
      "Epoch 150/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 4409.9971\n",
      "Epoch 151/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 4399.8994\n",
      "Epoch 152/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 4389.6143\n",
      "Epoch 153/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 4379.2314\n",
      "Epoch 154/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 4369.0098\n",
      "Epoch 155/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 4358.8926\n",
      "Epoch 156/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 4348.7407\n",
      "Epoch 157/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 4338.4854\n",
      "Epoch 158/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 4328.3242\n",
      "Epoch 159/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 4318.3433\n",
      "Epoch 160/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 4307.9468\n",
      "Epoch 161/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 4297.8491\n",
      "Epoch 162/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 4287.9702\n",
      "Epoch 163/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 4277.8486\n",
      "Epoch 164/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 4267.6719\n",
      "Epoch 165/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 4257.6616\n",
      "Epoch 166/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 4247.6099\n",
      "Epoch 167/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 4237.5288\n",
      "Epoch 168/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 4227.6680\n",
      "Epoch 169/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 4217.7407\n",
      "Epoch 170/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 4207.5654\n",
      "Epoch 171/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 4197.6392\n",
      "Epoch 172/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 4187.8970\n",
      "Epoch 173/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 4177.9800\n",
      "Epoch 174/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 4167.9448\n",
      "Epoch 175/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 4158.2852\n",
      "Epoch 176/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 4148.3086\n",
      "Epoch 177/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 4138.3818\n",
      "Epoch 178/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 4128.7476\n",
      "Epoch 179/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 4118.8052\n",
      "Epoch 180/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 4109.0869\n",
      "Epoch 181/500\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 4099.2134\n",
      "Epoch 182/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 4089.3560\n",
      "Epoch 183/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 4079.7017\n",
      "Epoch 184/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 4069.9314\n",
      "Epoch 185/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 4060.3936\n",
      "Epoch 186/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 4050.7207\n",
      "Epoch 187/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 4040.8989\n",
      "Epoch 188/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 4031.3726\n",
      "Epoch 189/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 4021.5415\n",
      "Epoch 190/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 4012.0532\n",
      "Epoch 191/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 4002.3774\n",
      "Epoch 192/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 3992.7366\n",
      "Epoch 193/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 3983.2527\n",
      "Epoch 194/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 3973.6504\n",
      "Epoch 195/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3964.0752\n",
      "Epoch 196/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3954.6606\n",
      "Epoch 197/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 3945.1362\n",
      "Epoch 198/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 3935.6689\n",
      "Epoch 199/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 3926.1455\n",
      "Epoch 200/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 3916.7456\n",
      "Epoch 201/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 3907.2676\n",
      "Epoch 202/500\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3897.9170\n",
      "Epoch 203/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3888.3232\n",
      "Epoch 204/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 3878.9531\n",
      "Epoch 205/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 3869.5493\n",
      "Epoch 206/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 3860.3735\n",
      "Epoch 207/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 3851.0352\n",
      "Epoch 208/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 3841.5557\n",
      "Epoch 209/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3832.1331\n",
      "Epoch 210/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 3822.9778\n",
      "Epoch 211/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 3813.6658\n",
      "Epoch 212/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 3804.5684\n",
      "Epoch 213/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3795.1802\n",
      "Epoch 214/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3785.8286\n",
      "Epoch 215/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 3776.6299\n",
      "Epoch 216/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3767.4351\n",
      "Epoch 217/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3758.4858\n",
      "Epoch 218/500\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 3749.2156\n",
      "Epoch 219/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3740.0969\n",
      "Epoch 220/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 3730.9788\n",
      "Epoch 221/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3721.7275\n",
      "Epoch 222/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 3712.6841\n",
      "Epoch 223/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3703.6099\n",
      "Epoch 224/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3694.5430\n",
      "Epoch 225/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3685.3726\n",
      "Epoch 226/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3676.1992\n",
      "Epoch 227/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 3667.3318\n",
      "Epoch 228/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 3658.3953\n",
      "Epoch 229/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3649.3193\n",
      "Epoch 230/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 3640.3147\n",
      "Epoch 231/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 3631.3306\n",
      "Epoch 232/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 3622.6643\n",
      "Epoch 233/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 3613.6680\n",
      "Epoch 234/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 3604.4854\n",
      "Epoch 235/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 3595.7690\n",
      "Epoch 236/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 3586.8025\n",
      "Epoch 237/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 3578.0154\n",
      "Epoch 238/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 3569.0732\n",
      "Epoch 239/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3560.3955\n",
      "Epoch 240/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3551.3325\n",
      "Epoch 241/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 3542.7742\n",
      "Epoch 242/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3533.8755\n",
      "Epoch 243/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3525.0220\n",
      "Epoch 244/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 3516.3538\n",
      "Epoch 245/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 3507.5908\n",
      "Epoch 246/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 3498.8047\n",
      "Epoch 247/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 3490.0242\n",
      "Epoch 248/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 3481.5269\n",
      "Epoch 249/500\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3472.8174\n",
      "Epoch 250/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 3464.1323\n",
      "Epoch 251/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 3455.4014\n",
      "Epoch 252/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 3446.7803\n",
      "Epoch 253/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 3438.3047\n",
      "Epoch 254/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 3429.6809\n",
      "Epoch 255/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 3420.9634\n",
      "Epoch 256/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3412.3665\n",
      "Epoch 257/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 3403.8252\n",
      "Epoch 258/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 3395.3262\n",
      "Epoch 259/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3386.7832\n",
      "Epoch 260/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 3378.2886\n",
      "Epoch 261/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 3369.8276\n",
      "Epoch 262/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 3361.2771\n",
      "Epoch 263/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 3352.7539\n",
      "Epoch 264/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3344.4595\n",
      "Epoch 265/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 3335.8843\n",
      "Epoch 266/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3327.6060\n",
      "Epoch 267/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3319.0386\n",
      "Epoch 268/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3310.7957\n",
      "Epoch 269/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3302.2844\n",
      "Epoch 270/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 3293.8240\n",
      "Epoch 271/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 3285.5454\n",
      "Epoch 272/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3277.3350\n",
      "Epoch 273/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 3269.0869\n",
      "Epoch 274/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 3260.7456\n",
      "Epoch 275/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 3252.2920\n",
      "Epoch 276/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 3244.1663\n",
      "Epoch 277/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 3235.7739\n",
      "Epoch 278/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 3227.5576\n",
      "Epoch 279/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 3219.2639\n",
      "Epoch 280/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 3211.2070\n",
      "Epoch 281/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 3202.9951\n",
      "Epoch 282/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 3194.8352\n",
      "Epoch 283/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 3186.5825\n",
      "Epoch 284/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 3178.4465\n",
      "Epoch 285/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 3170.3120\n",
      "Epoch 286/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 3162.2576\n",
      "Epoch 287/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 3154.2144\n",
      "Epoch 288/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 3146.0771\n",
      "Epoch 289/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3137.7700\n",
      "Epoch 290/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 3129.7930\n",
      "Epoch 291/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 3121.8162\n",
      "Epoch 292/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3113.7175\n",
      "Epoch 293/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 3105.6711\n",
      "Epoch 294/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3097.7263\n",
      "Epoch 295/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 3089.6763\n",
      "Epoch 296/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 3081.7192\n",
      "Epoch 297/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3073.7451\n",
      "Epoch 298/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 3065.8557\n",
      "Epoch 299/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 3057.9570\n",
      "Epoch 300/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 3050.1362\n",
      "Epoch 301/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 3041.9844\n",
      "Epoch 302/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 3034.2764\n",
      "Epoch 303/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 3026.2480\n",
      "Epoch 304/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 3018.5229\n",
      "Epoch 305/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 3010.7566\n",
      "Epoch 306/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 3002.7874\n",
      "Epoch 307/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2994.9585\n",
      "Epoch 308/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2987.0889\n",
      "Epoch 309/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 2979.3208\n",
      "Epoch 310/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2971.5928\n",
      "Epoch 311/500\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 2963.9104\n",
      "Epoch 312/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2956.0544\n",
      "Epoch 313/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 2948.4109\n",
      "Epoch 314/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2940.6226\n",
      "Epoch 315/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 2932.8169\n",
      "Epoch 316/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2925.2354\n",
      "Epoch 317/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2917.6401\n",
      "Epoch 318/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 2909.7803\n",
      "Epoch 319/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2902.2632\n",
      "Epoch 320/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2894.5928\n",
      "Epoch 321/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2886.9424\n",
      "Epoch 322/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2879.4019\n",
      "Epoch 323/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 2871.8335\n",
      "Epoch 324/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2864.3503\n",
      "Epoch 325/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2856.6074\n",
      "Epoch 326/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 2849.2346\n",
      "Epoch 327/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2841.5088\n",
      "Epoch 328/500\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2834.0708\n",
      "Epoch 329/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2826.5505\n",
      "Epoch 330/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2818.9233\n",
      "Epoch 331/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 2811.6055\n",
      "Epoch 332/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2804.1323\n",
      "Epoch 333/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2796.6045\n",
      "Epoch 334/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2789.3643\n",
      "Epoch 335/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 2781.7590\n",
      "Epoch 336/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 2774.3726\n",
      "Epoch 337/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2767.1355\n",
      "Epoch 338/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2759.6245\n",
      "Epoch 339/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 2752.1858\n",
      "Epoch 340/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2744.8555\n",
      "Epoch 341/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2737.4507\n",
      "Epoch 342/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 2730.2041\n",
      "Epoch 343/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2722.9019\n",
      "Epoch 344/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 2715.7607\n",
      "Epoch 345/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2708.3499\n",
      "Epoch 346/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 2701.1543\n",
      "Epoch 347/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2693.7183\n",
      "Epoch 348/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2686.6562\n",
      "Epoch 349/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 2679.2283\n",
      "Epoch 350/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 2672.0261\n",
      "Epoch 351/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 2664.8977\n",
      "Epoch 352/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2657.7153\n",
      "Epoch 353/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 2650.6157\n",
      "Epoch 354/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2643.4004\n",
      "Epoch 355/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2636.1694\n",
      "Epoch 356/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2629.2756\n",
      "Epoch 357/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2622.0271\n",
      "Epoch 358/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 2614.9541\n",
      "Epoch 359/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 2607.6875\n",
      "Epoch 360/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 2600.7434\n",
      "Epoch 361/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 2593.7122\n",
      "Epoch 362/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 2586.6348\n",
      "Epoch 363/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2579.5327\n",
      "Epoch 364/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2572.4111\n",
      "Epoch 365/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 2565.4741\n",
      "Epoch 366/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2558.6211\n",
      "Epoch 367/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2551.4258\n",
      "Epoch 368/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2544.5884\n",
      "Epoch 369/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 2537.6230\n",
      "Epoch 370/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2530.7500\n",
      "Epoch 371/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2523.6621\n",
      "Epoch 372/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2516.6499\n",
      "Epoch 373/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 2509.9358\n",
      "Epoch 374/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2502.9075\n",
      "Epoch 375/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2496.0579\n",
      "Epoch 376/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2489.2109\n",
      "Epoch 377/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 2482.5801\n",
      "Epoch 378/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2475.5566\n",
      "Epoch 379/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2468.6421\n",
      "Epoch 380/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2462.0244\n",
      "Epoch 381/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2455.0217\n",
      "Epoch 382/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 2448.4749\n",
      "Epoch 383/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2441.4438\n",
      "Epoch 384/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2434.7832\n",
      "Epoch 385/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2427.9536\n",
      "Epoch 386/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2421.2913\n",
      "Epoch 387/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2414.6135\n",
      "Epoch 388/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2407.9658\n",
      "Epoch 389/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2401.2808\n",
      "Epoch 390/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2394.3787\n",
      "Epoch 391/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 2387.8298\n",
      "Epoch 392/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2381.2061\n",
      "Epoch 393/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2374.5269\n",
      "Epoch 394/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 2367.8547\n",
      "Epoch 395/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 2361.3430\n",
      "Epoch 396/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 2354.8174\n",
      "Epoch 397/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2348.0908\n",
      "Epoch 398/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2341.4124\n",
      "Epoch 399/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2335.0261\n",
      "Epoch 400/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2328.3372\n",
      "Epoch 401/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2321.9668\n",
      "Epoch 402/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2315.4006\n",
      "Epoch 403/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 2308.8428\n",
      "Epoch 404/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2302.2622\n",
      "Epoch 405/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2295.7805\n",
      "Epoch 406/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 2289.2302\n",
      "Epoch 407/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2282.8066\n",
      "Epoch 408/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2276.5273\n",
      "Epoch 409/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 2270.0181\n",
      "Epoch 410/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 2263.6484\n",
      "Epoch 411/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 2257.2285\n",
      "Epoch 412/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 2250.7874\n",
      "Epoch 413/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 2244.3689\n",
      "Epoch 414/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2237.8132\n",
      "Epoch 415/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2231.6548\n",
      "Epoch 416/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 2225.3066\n",
      "Epoch 417/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2219.0269\n",
      "Epoch 418/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2212.5120\n",
      "Epoch 419/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2206.2412\n",
      "Epoch 420/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2200.1367\n",
      "Epoch 421/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2193.6042\n",
      "Epoch 422/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2187.5598\n",
      "Epoch 423/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2181.1213\n",
      "Epoch 424/500\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2175.0857\n",
      "Epoch 425/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2168.7629\n",
      "Epoch 426/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2162.4482\n",
      "Epoch 427/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2156.1677\n",
      "Epoch 428/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 2150.0686\n",
      "Epoch 429/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 2143.9131\n",
      "Epoch 430/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2137.7031\n",
      "Epoch 431/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2131.6008\n",
      "Epoch 432/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2125.3508\n",
      "Epoch 433/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2119.4211\n",
      "Epoch 434/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2113.0247\n",
      "Epoch 435/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2106.9968\n",
      "Epoch 436/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2101.0791\n",
      "Epoch 437/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2094.8169\n",
      "Epoch 438/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2088.7861\n",
      "Epoch 439/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2082.7974\n",
      "Epoch 440/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2076.7437\n",
      "Epoch 441/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 2070.6196\n",
      "Epoch 442/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 2064.5315\n",
      "Epoch 443/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 2058.6726\n",
      "Epoch 444/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2052.5776\n",
      "Epoch 445/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2046.5642\n",
      "Epoch 446/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2040.5763\n",
      "Epoch 447/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2034.5872\n",
      "Epoch 448/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 2028.8254\n",
      "Epoch 449/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 2022.8462\n",
      "Epoch 450/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2016.8157\n",
      "Epoch 451/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 2010.9189\n",
      "Epoch 452/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 2005.1042\n",
      "Epoch 453/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1999.1063\n",
      "Epoch 454/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1993.3152\n",
      "Epoch 455/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1987.4088\n",
      "Epoch 456/500\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1981.3661\n",
      "Epoch 457/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1975.6628\n",
      "Epoch 458/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1969.7341\n",
      "Epoch 459/500\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1964.0621\n",
      "Epoch 460/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1958.3201\n",
      "Epoch 461/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1952.3524\n",
      "Epoch 462/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1946.5574\n",
      "Epoch 463/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1940.8390\n",
      "Epoch 464/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1935.1093\n",
      "Epoch 465/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1929.4307\n",
      "Epoch 466/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1923.6736\n",
      "Epoch 467/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1918.0100\n",
      "Epoch 468/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1912.0845\n",
      "Epoch 469/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1906.4447\n",
      "Epoch 470/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1900.7734\n",
      "Epoch 471/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1895.2666\n",
      "Epoch 472/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1889.4512\n",
      "Epoch 473/500\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1883.8698\n",
      "Epoch 474/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1878.2032\n",
      "Epoch 475/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1872.6484\n",
      "Epoch 476/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1866.8569\n",
      "Epoch 477/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1861.3290\n",
      "Epoch 478/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1855.8169\n",
      "Epoch 479/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1850.0660\n",
      "Epoch 480/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1844.4641\n",
      "Epoch 481/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1839.1217\n",
      "Epoch 482/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1833.4623\n",
      "Epoch 483/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1827.8435\n",
      "Epoch 484/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1822.4155\n",
      "Epoch 485/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1817.0148\n",
      "Epoch 486/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1811.3303\n",
      "Epoch 487/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1805.8691\n",
      "Epoch 488/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1800.3984\n",
      "Epoch 489/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1795.0082\n",
      "Epoch 490/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1789.4377\n",
      "Epoch 491/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1784.0542\n",
      "Epoch 492/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1778.6860\n",
      "Epoch 493/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1773.2487\n",
      "Epoch 494/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1767.6959\n",
      "Epoch 495/500\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1762.4700\n",
      "Epoch 496/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1757.1475\n",
      "Epoch 497/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1751.5952\n",
      "Epoch 498/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1746.3052\n",
      "Epoch 499/500\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1740.9395\n",
      "Epoch 500/500\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1735.6525\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16001de3a90>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=500, batch_size=1, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now investigate the predictions of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[80.],\n",
       "       [78.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 491ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[38.288692],\n",
       "       [38.29944 ]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[38.288692],\n",
       "       [38.29944 ]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "      <th>residual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80.0</td>\n",
       "      <td>38.288692</td>\n",
       "      <td>41.711308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>78.0</td>\n",
       "      <td>38.299438</td>\n",
       "      <td>39.700562</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   actual  predicted   residual\n",
       "0    80.0  38.288692  41.711308\n",
       "1    78.0  38.299438  39.700562"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame()\n",
    "\n",
    "results['actual'] = y_test.flatten()\n",
    "results['predicted'] = y_pred.flatten()\n",
    "results['residual'] = results['actual'] - results['predicted']\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot(results['actual'], label = 'actual')\n",
    "plt.plot(results['predicted'], label = 'predicted')\n",
    "plt.plot(results['residual'], label = 'residual')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the above graph isn't very interesting, as the dataset was very small (for illustration purposes). This smaller dataset makes it easier to see the structure of the data (since we can see every observation). For larger datasets, the approach is the same - only there will be more observations, possible different length timesteps, and different features."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
