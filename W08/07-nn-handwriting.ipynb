{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w0tyra0NWJvI"
   },
   "source": [
    "###  Subash Chandra Biswal (U77884251)\n",
    "\n",
    "## MNIST machine learning exercise\n",
    "\n",
    "In this exercise we will compare the performance of three different modeling approaches at predicting handwritten numbers. \n",
    "\n",
    "We use the MNIST data set;\n",
    "\n",
    "![mnist data](https://upload.wikimedia.org/wikipedia/commons/2/27/MnistExamples.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pmAFVhDJXFBb"
   },
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "48VnFR9cXFP0"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import datasets\n",
    "\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YI7yVb-VW2zi"
   },
   "source": [
    "## Load data and explore/get to know the data structure\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the MNIST digits dataset. It's originally from UCI machine learning library, but included in SKLearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "M8CjaVlYW2Jx",
    "outputId": "e90a4dd3-3781-477f-b02f-97ac3e75be91"
   },
   "outputs": [],
   "source": [
    "mnist = datasets.load_digits() # sklearn includes this data set .. https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the dataset is stored in a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "5pPXrazAfUoL",
    "outputId": "593b0df0-7b98-4c9b-e01d-36930d653723"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'images', 'DESCR'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
       "        ...,\n",
       "        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "        [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
       "        [ 0.,  0., 10., ..., 12.,  1.,  0.]]),\n",
       " 'target': array([0, 1, 2, ..., 8, 9, 8]),\n",
       " 'frame': None,\n",
       " 'feature_names': ['pixel_0_0',\n",
       "  'pixel_0_1',\n",
       "  'pixel_0_2',\n",
       "  'pixel_0_3',\n",
       "  'pixel_0_4',\n",
       "  'pixel_0_5',\n",
       "  'pixel_0_6',\n",
       "  'pixel_0_7',\n",
       "  'pixel_1_0',\n",
       "  'pixel_1_1',\n",
       "  'pixel_1_2',\n",
       "  'pixel_1_3',\n",
       "  'pixel_1_4',\n",
       "  'pixel_1_5',\n",
       "  'pixel_1_6',\n",
       "  'pixel_1_7',\n",
       "  'pixel_2_0',\n",
       "  'pixel_2_1',\n",
       "  'pixel_2_2',\n",
       "  'pixel_2_3',\n",
       "  'pixel_2_4',\n",
       "  'pixel_2_5',\n",
       "  'pixel_2_6',\n",
       "  'pixel_2_7',\n",
       "  'pixel_3_0',\n",
       "  'pixel_3_1',\n",
       "  'pixel_3_2',\n",
       "  'pixel_3_3',\n",
       "  'pixel_3_4',\n",
       "  'pixel_3_5',\n",
       "  'pixel_3_6',\n",
       "  'pixel_3_7',\n",
       "  'pixel_4_0',\n",
       "  'pixel_4_1',\n",
       "  'pixel_4_2',\n",
       "  'pixel_4_3',\n",
       "  'pixel_4_4',\n",
       "  'pixel_4_5',\n",
       "  'pixel_4_6',\n",
       "  'pixel_4_7',\n",
       "  'pixel_5_0',\n",
       "  'pixel_5_1',\n",
       "  'pixel_5_2',\n",
       "  'pixel_5_3',\n",
       "  'pixel_5_4',\n",
       "  'pixel_5_5',\n",
       "  'pixel_5_6',\n",
       "  'pixel_5_7',\n",
       "  'pixel_6_0',\n",
       "  'pixel_6_1',\n",
       "  'pixel_6_2',\n",
       "  'pixel_6_3',\n",
       "  'pixel_6_4',\n",
       "  'pixel_6_5',\n",
       "  'pixel_6_6',\n",
       "  'pixel_6_7',\n",
       "  'pixel_7_0',\n",
       "  'pixel_7_1',\n",
       "  'pixel_7_2',\n",
       "  'pixel_7_3',\n",
       "  'pixel_7_4',\n",
       "  'pixel_7_5',\n",
       "  'pixel_7_6',\n",
       "  'pixel_7_7'],\n",
       " 'target_names': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       " 'images': array([[[ 0.,  0.,  5., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 13., ..., 15.,  5.,  0.],\n",
       "         [ 0.,  3., 15., ..., 11.,  8.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  4., 11., ..., 12.,  7.,  0.],\n",
       "         [ 0.,  2., 14., ..., 12.,  0.,  0.],\n",
       "         [ 0.,  0.,  6., ...,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ...,  5.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  9.,  0.,  0.],\n",
       "         [ 0.,  0.,  3., ...,  6.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ..., 10.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ..., 12.,  0.,  0.],\n",
       "         [ 0.,  0.,  3., ..., 14.,  0.,  0.],\n",
       "         [ 0.,  0.,  8., ..., 16.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  9., 16., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  3., 13., ..., 11.,  5.,  0.],\n",
       "         [ 0.,  0.,  0., ..., 16.,  9.,  0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0.,  0.,  1., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 13., ...,  2.,  1.,  0.],\n",
       "         [ 0.,  0., 16., ..., 16.,  5.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0., 16., ..., 15.,  0.,  0.],\n",
       "         [ 0.,  0., 15., ..., 16.,  0.,  0.],\n",
       "         [ 0.,  0.,  2., ...,  6.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  2., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0., 14., ..., 15.,  1.,  0.],\n",
       "         [ 0.,  4., 16., ..., 16.,  7.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  0., ..., 16.,  2.,  0.],\n",
       "         [ 0.,  0.,  4., ..., 16.,  2.,  0.],\n",
       "         [ 0.,  0.,  5., ..., 12.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0., 10., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  2., 16., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 15., ..., 15.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  4., 16., ..., 16.,  6.,  0.],\n",
       "         [ 0.,  8., 16., ..., 16.,  8.,  0.],\n",
       "         [ 0.,  1.,  8., ..., 12.,  1.,  0.]]]),\n",
       " 'DESCR': \".. _digits_dataset:\\n\\nOptical recognition of handwritten digits dataset\\n--------------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 1797\\n    :Number of Attributes: 64\\n    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\\n    :Missing Attribute Values: None\\n    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\\n    :Date: July; 1998\\n\\nThis is a copy of the test set of the UCI ML hand-written digits datasets\\nhttps://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\\n\\nThe data set contains images of hand-written digits: 10 classes where\\neach class refers to a digit.\\n\\nPreprocessing programs made available by NIST were used to extract\\nnormalized bitmaps of handwritten digits from a preprinted form. From a\\ntotal of 43 people, 30 contributed to the training set and different 13\\nto the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\\n4x4 and the number of on pixels are counted in each block. This generates\\nan input matrix of 8x8 where each element is an integer in the range\\n0..16. This reduces dimensionality and gives invariance to small\\ndistortions.\\n\\nFor info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\\nT. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\\nL. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\\n1994.\\n\\n.. topic:: References\\n\\n  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\\n    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\\n    Graduate Studies in Science and Engineering, Bogazici University.\\n  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\\n  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\\n    Linear dimensionalityreduction using relevance weighted LDA. School of\\n    Electrical and Electronic Engineering Nanyang Technological University.\\n    2005.\\n  - Claudio Gentile. A New Approximate Maximal Margin Classification\\n    Algorithm. NIPS. 2000.\\n\"}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note thjat there are 1797 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "rTQ7qNp4ffaW",
    "outputId": "3d267533-ac01-4747-abee-369aae5d3d79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1797\n"
     ]
    }
   ],
   "source": [
    "print(len(mnist.data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Images are 8x8 grid of values epresenting the gray level for each pixel (16 levels of grey -- from 0 (black) to 15 (white)). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "id": "B0ZaSvLlfva0",
    "outputId": "7735e16a-6f2e-41cd-e4e3-55c1dbd5a89d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  2., 13.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  8., 15.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  5., 16.,  5.,  2.,  0.,  0.],\n",
       "       [ 0.,  0., 15., 12.,  1., 16.,  4.,  0.],\n",
       "       [ 0.,  4., 16.,  2.,  9., 16.,  8.,  0.],\n",
       "       [ 0.,  0., 10., 14., 16., 16.,  4.,  0.],\n",
       "       [ 0.,  0.,  0.,  0., 13.,  8.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0., 13.,  6.,  0.,  0.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.images[100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To analyze this, we simple turn this into a one dimensional array (so we will x1, x2, ... x63, x64). This has already been done for us, and is stored in the data key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "id": "sjDP19CWfT6S",
    "outputId": "f3643de4-6fc9-4810-d5d5-21fb633970fa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.,  0.,  0., 13., 15., 10.,\n",
       "       15.,  5.,  0.,  0.,  3., 15.,  2.,  0., 11.,  8.,  0.,  0.,  4.,\n",
       "       12.,  0.,  0.,  8.,  8.,  0.,  0.,  5.,  8.,  0.,  0.,  9.,  8.,\n",
       "        0.,  0.,  4., 11.,  0.,  1., 12.,  7.,  0.,  0.,  2., 14.,  5.,\n",
       "       10., 12.,  0.,  0.,  0.,  0.,  6., 13., 10.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "id": "Pi5Fvsd_dry5",
    "outputId": "d61e56b6-99c4-486c-b4fa-523f3cb7f1d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "print(mnist.target[0])\n",
    "print(mnist.target[1])\n",
    "print(mnist.target[2])\n",
    "print(mnist.target[3])\n",
    "print(mnist.target[4])\n",
    "print(mnist.target[5])\n",
    "print(mnist.target[6])\n",
    "print(mnist.target[7])\n",
    "print(mnist.target[8])\n",
    "print(mnist.target[9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use matplotlib to display a sample of these images from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "qW162_28WC60",
    "outputId": "c7bf771d-ebd1-4a42-e9e4-719d243b814a"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPUAAAD4CAYAAAA0L6C7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAK30lEQVR4nO3d34tc9RnH8c+nq6H1FwutLZqEroIEpNCNhIAExMa2xCpuLnqRgMWVQq4UpQXRXqV/gJJeFGGJGsFUaeNPxGoFjVZorfmxaY0bSxpSso02SglGC12iTy92UqJdu2dmzvmes0/fLwjuzg77fYb4zpmdPXO+jggByOMLbQ8AoF5EDSRD1EAyRA0kQ9RAMuc08U1tp3xJfdmyZUXXW7lyZbG1RkdHi6116tSpYmsdPXq02FqSNDc3V2ytiPBCtzcSdVaXXnpp0fXuvffeYmtNTEwUW+uVV14pttbk5GSxtaTy/4gshKffQDJEDSRD1EAyRA0kQ9RAMkQNJEPUQDJEDSRD1EAylaK2vcH227YP27676aEADG7RqG2PSPq5pOslXSlps+0rmx4MwGCqHKnXSjocEUciYk7SY5LKnSgMoC9Vol4u6dhZn8/2bvsU21ts77G9p67hAPSvyru0Fnp713+9tTIipiRNSXnfegksBVWO1LOSzn5j7wpJx5sZB8CwqkT9hqQrbF9me5mkTZKeaXYsAINa9Ol3RJy2fZukFySNSHowIg42PhmAgVS68klEPCfpuYZnAVADzigDkiFqIBmiBpIhaiAZogaSIWogGaIGknETm85nPff7qaeeKrre7t27i601PT1dbK3x8fFia5XcTkiStm7dWmytz9t2hyM1kAxRA8kQNZAMUQPJEDWQDFEDyRA1kAxRA8kQNZAMUQPJVNmh40HbJ2y/WWIgAMOpcqTeIWlDw3MAqMmiUUfEq5L+UWAWADWodDXRKmxvkbSlru8HYDC1Rc22O0A38Oo3kAxRA8lU+ZXWo5J+J2mV7VnbP2x+LACDqrKX1uYSgwCoB0+/gWSIGkiGqIFkiBpIhqiBZIgaSIaogWRqO/e7LRMTE8XWKrldjCRt27at2Folt/i59tpri61V8nF1BUdqIBmiBpIhaiAZogaSIWogGaIGkiFqIBmiBpIhaiAZogaSqXKNspW2X7Y9Y/ug7TtKDAZgMFXO/T4t6ccRsc/2hZL22n4xIt5qeDYAA6iy7c47EbGv9/EpSTOSljc9GIDB9PUuLdtjklZLen2Br7HtDtABlaO2fYGkxyXdGREffPbrbLsDdEOlV79tn6v5oHdGxBPNjgRgGFVe/bakByTNRMR9zY8EYBhVjtTrJP1A0nrb070/32t4LgADqrLtzmuSXGAWADXgjDIgGaIGkiFqIBmiBpIhaiAZogaSIWogGaIGklnye2kdOHCg2Fqjo6PF1pKkjRs3FltrbGys2Fol9yTbunVrsbW6giM1kAxRA8kQNZAMUQPJEDWQDFEDyRA1kAxRA8kQNZBMlQsPftH2H2wf6G2789MSgwEYTJXTRP8laX1EfNi7VPBrtn8dEb9veDYAA6hy4cGQ9GHv03N7f7hYP9BRVS/mP2J7WtIJSS9GxILb7tjeY3tPzTMC6EOlqCPi44gYl7RC0lrb31jgPlMRsSYi1tQ8I4A+9PXqd0SclLRb0oYmhgEwvCqvfl9se7T38ZckfVvSoYbnAjCgKq9+XyLpYdsjmv9H4JcR8WyzYwEYVJVXv/+o+T2pASwBnFEGJEPUQDJEDSRD1EAyRA0kQ9RAMkQNJEPUQDKef2dlzd/UTvnWzJLbxUjS/v37i6319NNPF1ur5HZCmUWEF7qdIzWQDFEDyRA1kAxRA8kQNZAMUQPJEDWQDFEDyRA1kAxRA8lUjrp3Qf/9trnoINBh/Ryp75A009QgAOpRddudFZJukLS92XEADKvqkXqbpLskffJ5d2AvLaAbquzQcaOkExGx93/dj720gG6ocqReJ+km20clPSZpve1HGp0KwMAWjToi7omIFRExJmmTpJci4ubGJwMwEH5PDSRTZYO8/4iI3ZrfyhZAR3GkBpIhaiAZogaSIWogGaIGkiFqIBmiBpLp6/fU/+8mJyeLrnfgwIGi6yEHjtRAMkQNJEPUQDJEDSRD1EAyRA0kQ9RAMkQNJEPUQDJEDSRT6TTR3pVET0n6WNJpLgMMdFc/535/KyLeb2wSALXg6TeQTNWoQ9JvbO+1vWWhO7DtDtANVZ9+r4uI47a/KulF24ci4tWz7xARU5KmJMl21DwngIoqHakj4njvvyckPSlpbZNDARhclQ3yzrd94ZmPJX1X0ptNDwZgMFWefn9N0pO2z9z/FxHxfKNTARjYolFHxBFJ3ywwC4Aa8CstIBmiBpIhaiAZogaSIWogGaIGkiFqIBm23enD+Ph40fWmp6eLrXXLLbcUW2t0dLTYWidPniy2VldwpAaSIWogGaIGkiFqIBmiBpIhaiAZogaSIWogGaIGkiFqIJlKUdsetb3L9iHbM7avbnowAIOpeu73zyQ9HxHft71M0nkNzgRgCItGbfsiSddImpSkiJiTNNfsWAAGVeXp9+WS3pP0kO39trf3rv/9KWy7A3RDlajPkXSVpPsjYrWkjyTd/dk7RcRURKxhm1ugXVWinpU0GxGv9z7fpfnIAXTQolFHxLuSjtle1bvpOklvNToVgIFVffX7dkk7e698H5F0a3MjARhGpagjYloSPysDSwBnlAHJEDWQDFEDyRA1kAxRA8kQNZAMUQPJEDWQDHtp9WFycrLoejt27Ci6XiljY2PF1iq5H1lXcKQGkiFqIBmiBpIhaiAZogaSIWogGaIGkiFqIBmiBpJZNGrbq2xPn/XnA9t3FpgNwAAWPU00It6WNC5Jtkck/U3Sk82OBWBQ/T79vk7SXyLir00MA2B4/b6hY5OkRxf6gu0tkrYMPRGAoVQ+Uveu+X2TpF8t9HW23QG6oZ+n39dL2hcRf29qGADD6yfqzfqcp94AuqNS1LbPk/QdSU80Ow6AYVXdduefkr7c8CwAasAZZUAyRA0kQ9RAMkQNJEPUQDJEDSRD1EAyRA0k44io/5va70nq9+2ZX5H0fu3DdEPWx8bjas/XI+Lihb7QSNSDsL0n6zu8sj42Hlc38fQbSIaogWS6FPVU2wM0KOtj43F1UGd+pgZQjy4dqQHUgKiBZDoRte0Ntt+2fdj23W3PUwfbK22/bHvG9kHbd7Q9U51sj9jeb/vZtmepk+1R27tsH+r93V3d9kz9av1n6t4GAX/W/OWSZiW9IWlzRLzV6mBDsn2JpEsiYp/tCyXtlbRxqT+uM2z/SNIaSRdFxI1tz1MX2w9L+m1EbO9dQfe8iDjZ8lh96cKReq2kwxFxJCLmJD0maaLlmYYWEe9ExL7ex6ckzUha3u5U9bC9QtINkra3PUudbF8k6RpJD0hSRMwttaClbkS9XNKxsz6fVZL/+c+wPSZptaTXWx6lLtsk3SXpk5bnqNvlkt6T9FDvR4vtts9ve6h+dSFqL3Bbmt+z2b5A0uOS7oyID9qeZ1i2b5R0IiL2tj1LA86RdJWk+yNitaSPJC2513i6EPWspJVnfb5C0vGWZqmV7XM1H/TOiMhyeeV1km6yfVTzPyqtt/1IuyPVZlbSbESceUa1S/ORLyldiPoNSVfYvqz3wsQmSc+0PNPQbFvzP5vNRMR9bc9Tl4i4JyJWRMSY5v+uXoqIm1seqxYR8a6kY7ZX9W66TtKSe2Gz3w3yahcRp23fJukFSSOSHoyIgy2PVYd1kn4g6U+2p3u3/SQinmtvJFRwu6SdvQPMEUm3tjxP31r/lRaAenXh6TeAGhE1kAxRA8kQNZAMUQPJEDWQDFEDyfwb00qLHgpv5UgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in np.random.choice(range(0,len(mnist.images)), 4): # choose 4 at random\n",
    "  plt.imshow(mnist.images[i], cmap='gray')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into training and test sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(mnist.data, mnist.target, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "5WfGTWb3hYd-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 547 ms\n",
      "Wall time: 4.07 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "ann = MLPClassifier(hidden_layer_sizes=(60,50,40), solver='adam', max_iter=200)\n",
    "_ = ann.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = ann.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.98        43\n",
      "           1       1.00      1.00      1.00        35\n",
      "           2       0.97      1.00      0.99        36\n",
      "           3       0.95      0.98      0.96        41\n",
      "           4       0.95      0.97      0.96        38\n",
      "           5       0.97      0.97      0.97        30\n",
      "           6       1.00      1.00      1.00        37\n",
      "           7       0.97      0.95      0.96        37\n",
      "           8       0.96      0.93      0.95        29\n",
      "           9       0.94      0.97      0.96        34\n",
      "\n",
      "    accuracy                           0.97       360\n",
      "   macro avg       0.97      0.97      0.97       360\n",
      "weighted avg       0.97      0.97      0.97       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "{'solver': 'adam', 'max_iter': 5000, 'learning_rate_init': 0.001, 'learning_rate': 'constant', 'hidden_layer_sizes': (70,), 'alpha': 0.5, 'activation': 'tanh'}\n",
      "CPU times: total: 4.17 s\n",
      "Wall time: 5min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "score_measure = \"accuracy\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [ (50,), (70,),(50,30), (40,20), (60,40, 20), (70,50,40)],\n",
    "    'activation': ['logistic', 'tanh', 'relu'],\n",
    "    'solver': ['adam', 'sgd'],\n",
    "    'alpha': [0, .2, .5, .7, 1],\n",
    "    'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "    'learning_rate_init': [0.001, 0.01, 0.1, 0.2, 0.5],\n",
    "    'max_iter': [5000]\n",
    "}\n",
    "\n",
    "ann = MLPClassifier()\n",
    "grid_search = RandomizedSearchCV(estimator = ann, param_distributions=param_grid, cv=kfolds, n_iter=100,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "bestRecallTree = grid_search.best_estimator_\n",
    "\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scbis\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:292: UserWarning: The total space of parameters 200 is smaller than n_iter=500. Running 200 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n",
      "The best accuracy score is 0.9631339527680991\n",
      "... with parameters: {'n_estimators': 1000, 'max_depth': 2, 'learning_rate': 0.2}\n",
      "CPU times: total: 27.8 s\n",
      "Wall time: 20min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "score_measure = \"accuracy\"\n",
    "kfolds = 5\n",
    "xgboost = XGBClassifier()\n",
    "\n",
    "param_grid_xg = {  \n",
    "    'max_depth': range (2, 10, 1),\n",
    "    'n_estimators': [10,50,250,1000,2000],\n",
    "    'learning_rate': [1.0,0.2,0.1, 0.01, 0.05],}   \n",
    "\n",
    "rand_search_xg = RandomizedSearchCV(estimator = xgboost, param_distributions=param_grid_xg, cv=kfolds, n_iter=500,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "# XGBoost Classifier model fit for grid search\n",
    "_ = rand_search_xg.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search_xg.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search_xg.best_params_}\")\n",
    "\n",
    "bestRecallXg = rand_search_xg.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        43\n",
      "           1       0.97      1.00      0.99        35\n",
      "           2       1.00      1.00      1.00        36\n",
      "           3       0.98      1.00      0.99        41\n",
      "           4       1.00      1.00      1.00        38\n",
      "           5       0.93      0.93      0.93        30\n",
      "           6       1.00      1.00      1.00        37\n",
      "           7       1.00      0.97      0.99        37\n",
      "           8       1.00      0.93      0.96        29\n",
      "           9       0.94      0.97      0.96        34\n",
      "\n",
      "    accuracy                           0.98       360\n",
      "   macro avg       0.98      0.98      0.98       360\n",
      "weighted avg       0.98      0.98      0.98       360\n",
      "\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 9.22 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = bestRecallTree.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.95        43\n",
      "           1       0.97      1.00      0.99        35\n",
      "           2       1.00      0.97      0.99        36\n",
      "           3       1.00      0.95      0.97        41\n",
      "           4       0.95      1.00      0.97        38\n",
      "           5       0.91      1.00      0.95        30\n",
      "           6       1.00      1.00      1.00        37\n",
      "           7       1.00      0.97      0.99        37\n",
      "           8       0.90      0.93      0.92        29\n",
      "           9       0.94      0.91      0.93        34\n",
      "\n",
      "    accuracy                           0.97       360\n",
      "   macro avg       0.96      0.97      0.97       360\n",
      "weighted avg       0.97      0.97      0.97       360\n",
      "\n",
      "CPU times: total: 125 ms\n",
      "Wall time: 35.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = bestRecallXg.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "{'activation': 'tanh', 'alpha': 0.3, 'hidden_layer_sizes': (70,), 'learning_rate': 'constant', 'learning_rate_init': 0.005, 'max_iter': 5000, 'solver': 'adam'}\n",
      "CPU times: total: 1.42 s\n",
      "Wall time: 2min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "score_measure = \"accuracy\"\n",
    "kfolds = 5\n",
    "\n",
    "{'solver': 'adam', 'max_iter': 5000, 'learning_rate_init': 0.001, 'learning_rate': 'constant', 'hidden_layer_sizes': (70,), 'alpha': 0.5, 'activation': 'tanh'}\n",
    "\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(50,), (70,), (90,)],\n",
    "    'activation': ['tanh'],\n",
    "    'solver': ['adam'],\n",
    "    'alpha': [0.3 ,.5, .7],\n",
    "    'learning_rate': ['constant'],\n",
    "    'learning_rate_init': [0.0001,0.001,0.005],\n",
    "    'max_iter': [5000]\n",
    "}\n",
    "\n",
    "ann = MLPClassifier()\n",
    "grid_search = GridSearchCV(estimator = ann, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "bestRecallTree = grid_search.best_estimator_\n",
    "\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "The best accuracy score is 0.9631339527680991\n",
      "... with parameters: {'learning_rate': 0.2, 'max_depth': 2, 'n_estimators': 1000}\n",
      "CPU times: total: 39.1 s\n",
      "Wall time: 4min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    " {'n_estimators': 1000, 'max_depth': 2, 'learning_rate': 0.2}\n",
    "score_measure = \"accuracy\"\n",
    "kfolds = 5\n",
    "xgboost = XGBClassifier()\n",
    "\n",
    "param_grid_xg = {  \n",
    "    'max_depth': [1,2,3],\n",
    "    'n_estimators': [700, 1000, 1300],\n",
    "    'learning_rate': [0.1,0.2,0.1],}   \n",
    "\n",
    "grid_search_xg = GridSearchCV(estimator = xgboost, param_grid=param_grid_xg, cv=kfolds,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "# XGBoost Classifier model fit for grid search\n",
    "_ = grid_search_xg.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search_xg.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search_xg.best_params_}\")\n",
    "\n",
    "bestRecallXg = grid_search_xg.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        43\n",
      "           1       0.97      1.00      0.99        35\n",
      "           2       1.00      1.00      1.00        36\n",
      "           3       0.98      1.00      0.99        41\n",
      "           4       1.00      1.00      1.00        38\n",
      "           5       0.93      0.93      0.93        30\n",
      "           6       1.00      1.00      1.00        37\n",
      "           7       1.00      0.95      0.97        37\n",
      "           8       0.97      0.97      0.97        29\n",
      "           9       0.97      0.97      0.97        34\n",
      "\n",
      "    accuracy                           0.98       360\n",
      "   macro avg       0.98      0.98      0.98       360\n",
      "weighted avg       0.98      0.98      0.98       360\n",
      "\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 25.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = bestRecallTree.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.95        43\n",
      "           1       0.97      1.00      0.99        35\n",
      "           2       1.00      0.97      0.99        36\n",
      "           3       1.00      0.95      0.97        41\n",
      "           4       0.95      1.00      0.97        38\n",
      "           5       0.91      1.00      0.95        30\n",
      "           6       1.00      1.00      1.00        37\n",
      "           7       1.00      0.97      0.99        37\n",
      "           8       0.90      0.93      0.92        29\n",
      "           9       0.94      0.91      0.93        34\n",
      "\n",
      "    accuracy                           0.97       360\n",
      "   macro avg       0.96      0.97      0.97       360\n",
      "weighted avg       0.97      0.97      0.97       360\n",
      "\n",
      "CPU times: total: 93.8 ms\n",
      "Wall time: 33.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = bestRecallXg.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "I have used XGBoost as the second model for this classification dataset. Its observed that neural network model performed better (Accuracy = 0.98) than XGBoost (Accuracy = 0.97) for both random grid search and grid search. Though neural network takes bit more time than XGBoost, its worth it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOig4eSm144+FaPk1GKk187",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "mnist_compete_3_models.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "b056086e24cb5602cbcb82122035cd3d6ee2ccbf5df29c16e348c108b0f83be3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
